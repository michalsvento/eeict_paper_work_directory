 
@TechReport{Pascual2017,
  author     = {Pascual, Santiago and Bonafonte, Antonio and Serrà, Joan},
  title      = {{SEGAN}: {Speech} {Enhancement} {Generative} {Adversarial} {Network}},
  year       = {2017},
  month      = jun,
  note       = {arXiv:1703.09452 [cs] type: article},
  abstract   = {Current speech enhancement techniques operate on the spectral domain and/or exploit some higher-level feature. The majority of them tackle a limited number of noise conditions and rely on first-order statistics. To circumvent these issues, deep networks are being increasingly used, thanks to their ability to learn complex functions from large example sets. In this work, we propose the use of generative adversarial networks for speech enhancement. In contrast to current techniques, we operate at the waveform level, training the model end-to-end, and incorporate 28 speakers and 40 different noise conditions into the same model, such that model parameters are shared across them. We evaluate the proposed model using an independent, unseen test set with two speakers and 20 alternative noise conditions. The enhanced samples confirm the viability of the proposed model, and both objective and subjective evaluations confirm the effectiveness of it. With that, we open the exploration of generative architectures for speech enhancement, which may progressively incorporate further speech-centric design choices to improve their performance.},
  annote     = {Comment: 5 pages, 4 figures, accepted in INTERSPEECH 2017},
  doi        = {10.48550/arXiv.1703.09452},
  file       = {:Pascual2017 - SEGAN_ Speech Enhancement Generative Adversarial Network.pdf:PDF},
  keywords   = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Sound},
  school     = {arXiv},
  shorttitle = {{SEGAN}},
  url        = {http://arxiv.org/abs/1703.09452},
  urldate    = {2023-02-22},
}

 
@TechReport{Chan2016,
  author     = {Chan, Stanley H. and Wang, Xiran and Elgendy, Omar A.},
  title      = {Plug-and-{Play} {ADMM} for {Image} {Restoration}: {Fixed} {Point} {Convergence} and {Applications}},
  year       = {2016},
  month      = nov,
  note       = {arXiv:1605.01710 [cs] type: article},
  abstract   = {Alternating direction method of multiplier (ADMM) is a widely used algorithm for solving constrained optimization problems in image restoration. Among many useful features, one critical feature of the ADMM algorithm is its modular structure which allows one to plug in any off-the-shelf image denoising algorithm for a subproblem in the ADMM algorithm. Because of the plug-in nature, this type of ADMM algorithms is coined the name "Plug-and-Play ADMM". Plug-and-Play ADMM has demonstrated promising empirical results in a number of recent papers. However, it is unclear under what conditions and by using what denoising algorithms would it guarantee convergence. Also, since Plug-and-Play ADMM uses a specific way to split the variables, it is unclear if fast implementation can be made for common Gaussian and Poissonian image restoration problems. In this paper, we propose a Plug-and-Play ADMM algorithm with provable fixed point convergence. We show that for any denoising algorithm satisfying an asymptotic criteria, called bounded denoisers, Plug-and-Play ADMM converges to a fixed point under a continuation scheme. We also present fast implementations for two image restoration problems on super-resolution and single-photon imaging. We compare Plug-and-Play ADMM with state-of-the-art algorithms in each problem type, and demonstrate promising experimental results of the algorithm.},
  annote     = {Comment: 14 pages},
  doi        = {10.48550/arXiv.1605.01710},
  file       = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1605.01710.pdf:application/pdf},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition},
  school     = {arXiv},
  shorttitle = {Plug-and-{Play} {ADMM} for {Image} {Restoration}},
  url        = {http://arxiv.org/abs/1605.01710},
  urldate    = {2023-02-22},
}

 
@Article{Mokry2020,
  author     = {Mokrý, Ondřej and Rajmic, Pavel},
  journal    = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title      = {Audio {Inpainting}: {Revisited} and {Reweighted}},
  year       = {2020},
  issn       = {2329-9304},
  pages      = {2906--2918},
  volume     = {28},
  abstract   = {In this article, we deal with the problem of sparsity-based audio inpainting, i.e. filling in the missing segments of audio. A consequence of the approaches based on mathematical optimization is the insufficient amplitude of the signal in the filled gaps. Remaining in the framework based on sparsity and convex optimization, we propose improvements to audio inpainting, aiming at compensating for such an energy loss. The new ideas are based on different types of weighting, both in the coefficient and the time domains. We show that our propositions improve the inpainting performance in terms of both the SNR and ODG.},
  doi        = {10.1109/TASLP.2020.3030486},
  file       = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=9222235&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzkyMjIyMzU=:application/pdf},
  keywords   = {Transforms, Reliability, Speech processing, Microsoft Windows, Analytical models, Minimization, Time-domain analysis, Audio inpainting, sparse representations, proximal algorithms, Douglas–Rachford algorithm, Chambolle–Pock algorithm, energy loss compensation, amplitude drop},
  shorttitle = {Audio {Inpainting}},
}

 
@Article{Janssen1986,
  author   = {Janssen, A. and Veldhuis, R. and Vries, L.},
  journal  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title    = {Adaptive interpolation of discrete-time signals that can be modeled as autoregressive processes},
  year     = {1986},
  issn     = {0096-3518},
  month    = apr,
  number   = {2},
  pages    = {317--330},
  volume   = {34},
  abstract = {This paper presents an adaptive algorithm for the restoration of lost sample values in discrete-time signals that can locally be described by means of autoregressive processes. The only restrictions are that the positions of the unknown samples should be known and that they should be embedded in a sufficiently large neighborhood of known samples. The estimates of the unknown samples are obtained by minimizing the sum of squares of the residual errors that involve estimates of the autoregressive parameters. A statistical analysis shows that, for a burst of lost samples, the expected quadratic interpolation error per sample converges to the signal variance when the burst length tends to infinity. The method is in fact the first step of an iterative algorithm, in which in each iteration step the current estimates of the missing samples are used to compute the new estimates. Furthermore, the feasibility of implementation in hardware for real-time use is established. The method has been tested on artificially generated auto-regressive processes as well as on digitized music and speech signals.},
  doi      = {10.1109/TASSP.1986.1164824},
  file     = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=1164824&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzExNjQ4MjQ=:application/pdf},
  keywords = {Interpolation, Signal processing, Autoregressive processes, Adaptive algorithm, Signal restoration, Statistical analysis, H infinity control, Iterative algorithms, Hardware, Testing},
}

 
@Article{Etter1996,
  author   = {Etter, W.},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {Restoration of a discrete-time signal segment by interpolation based on the left-sided and right-sided autoregressive parameters},
  year     = {1996},
  issn     = {1941-0476},
  month    = may,
  number   = {5},
  pages    = {1124--1135},
  volume   = {44},
  abstract = {This paper presents an algorithm for the interpolation of a missing signal segment on the assumption that the signal can be modeled as an autoreg