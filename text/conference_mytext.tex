\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}

\usepackage{xcolor}
\newcommand{\todo}[1]{\textcolor{red}{#1}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

%\title{Audio restoration using plug-and-play approach\\
%	{}
%\thanks{Identify applicable funding agency here. If none, delete this.}
%}

\title{Joint audio denoising and inpainting with plug-and-play proximal algorithm}

\author{\IEEEauthorblockN{Michal Švento}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
%\textit{Brno University of Technology}\\
%Brno, Czech Republic \\
%212584@vut.cz}
\IEEEauthorblockA{
	\textit{Brno University of Technology, FEEC,} \\
	\textit{Department of Telecommunications,} \\
	Technická 12, 616 00 Brno, Czech Republic \\
	\href{mailto:212584@vut.cz}{212584@vut.cz}
}
\and
\IEEEauthorblockN{Ondřej Mokrý}
%\IEEEauthorblockA{\textit{Signal Processing Laboratory} \\
%\textit{Brno University of Technology}\\
%Brno, Czech Republic \\
%xmokry12@vut.cz}
\IEEEauthorblockA{
	\textit{Brno University of Technology, FEEC,} \\
	\textit{Department of Telecommunications,} \\
	Technická 12, 616 00 Brno, Czech Republic \\
	\href{mailto:xmokry12@vut.cz}{xmokry12@vut.cz}
}
}

\maketitle

\begin{abstract}
\todo{Plug-and-play má potenciál fungovat, přidání nějaké přibližné informace o některých vzorcích (to je zvýšení toho proj faktoru) v některých metrikách zlepšuje kvalitu a citlivost na tento parametr je výrazně nižší než u konvenční metody.}
\end{abstract}

\begin{IEEEkeywords}
speech enhancement, deep learning, denoising, Douglas--Rachford algorithm, inpainting
\end{IEEEkeywords}

\section{Introduction}

Audio enhancement tasks mostly face problems like missing or damaged samples, noise, or clipping.
Considering speech signals, we %should not avoid the intelligibility problems.
are not only interested in restoring the degradation sample by sample, but we also aim at improving the intelligibility of the recorded speech.
Each restoration problem has developed its own way of enhancing the signal.
Nowadays, the best way to differentiate algorithms is into two categories:
conventional, e.g.\ using autoregressive (AR) modeling or sparsity-based optimization, and solutions using deep learning.
The present paper focuses on the case of restoring a partially observed signal whose observed samples are further degraded by noise, i.e., the aim is to perform simultaneous inpainting and denoising of the speech signal.

In conventional approaches to inpainting, the AR-based Janssen \cite{Janssen1986} and Etter~\cite{Etter1996} algorithms dominate in terms of reconstruction quality.
% These approaches are based on autoregressive signal modeling \cite{Mokry2020}.
% Sparse signal representation has changed efficiency of restoration, mainly because increase of computing power.
A more recent, successful class of methods is based on sparsity.
The key idea is that after performing proper time-frequency analysis of an audio signal,
most of the information is concentrated in a few coefficients, i.e., it is sparse.
This can be applied as fitting the sparsest possible reconstruction either to the reliable observed samples \cite{Adler2012, Kitic2015, Zaviska2019, Mokry2019}, or to a signal not much diverging from the observation in the case of denoising \cite{Kowalski2013}.
% The information hidden in frequency representation (using proper time-frequency analysis) is sparse, i.e. we do not need each spectral coefficient to repair the signal with improved subjective results.
%The most advanced works using sparsity are \cite{Adler2012,Kitic2015,Zaviska2019, Mokry2019}.

Deep learning algorithms have also made their own progress in this area.
The most efficient neural network models are autoencoders,
recurrent neural networks (RNN) and
Generative Adversial Networks (GAN).
Current state-of-the-art deep learned algorithms are Speech Enhancement GAN (SEGAN) \cite{Pascual2017}, NSNet \cite{Xia2020}, FullSubNet \cite{Hao2021}.
While learning-based algorithms allow to adapt to real-world signals, rather than to rely on hand-crafted priors like sparsity or the AR nature of signals, they need large datasets for training.
Furthermore, neural networks are usually trained for a specific problem, lacking universal applicability on similar restoration tasks, in contrast to sparsity-based methods \cite{Gaultier2017, Mokry202021, Zaviska2021}.

As a compromise between the conventional and learning-based methods, 
% In \cite{Chan2016} was introduced Plug-and-Play method for image restoration.
the Plug-and-Play method for image restoration was introduced in \cite{Chan2016},
where part of each iteration of an optimization algorithm is replaced by a (learned) denoiser.
% The idea of a hybrid model,
% combining conventional approach (convex minimization) with deep learning,
% has shown succesful.
In the present paper, we propose a hybrid algorithm based on the same paradigm, aiming at restoration of degraded speech.
While \cite{Chan2016} focused on adapting the Alternating Direction method of Multipliers (ADMM) and a recent declipping approach used the learned element only partially \cite{Tanaka2022}, we choose an opposite approach by working with a simple Douglas--Rachford algorithm (DRA) and exploring the trade-off between data fitting and denoising in the algorithm.


%Our motivation is to transform this model to audio problems with minor differences.
%We replace Alternating Direction Multiplier Method (ADMM) with Douglas-Rachford algorithm (DR~algorithm).
%Denoiser will be chosen from state-of-the-art audio denoisers. 

%% Introduction to sections.
The paper is organized as follows. In section \ref{sec:prereq} we introduce the task from mathematical point of view and we define the restoration as a minimization task.
Section \ref{sec:plugaandplay} presents the Plug-and-Play method and its challenges.
Section \ref{sec:eval} discusses the results and further improvements of algorithm.
Finally, Section \ref{sec:conclusion} concludes the paper.

\section{Prerequsities}\label{sec:prereq} 

\todo{Asi můžeme nechat obě formulace, protože zapadají do příběhu -- máme formulaci pro koeficienty, která umožňuje formulovat DRA s projekcí a soft. My ale chceme upravovat proximální operátor definovaný na signálu, proto máme druhou formulaci a k ní příslušný (přibližný) algoritmus \ref{alg:DRA_t}.
U varianty koeficienty bych ale možná nechal formulaci, ale algoritmus \ref{alg:DRA_c} bych možná vypustil.}

In this section, we formulate the first task -- inpainting.
The proposed method \cite{Chan2016} assumes any damage,
but we start with missing samples and then expand the model for various damages.
The rest of the section explains minimization problem solved by DRA.
Solution has two approaches.
First, using frequency coefficients as input explained in \ref{subsec:freqcoef}~\cite{Mokry2020}.
Second, using samples in time domain is described in subsection \ref{subsec:timecoef} \cite{Mokry2021}.


\subsection{Task formulation}

We consider column vector $ \mathbf{s} \in \mathbb{R}^{N} $ as our observed damaged single-channel signal of length $ N $.
We have set $ I $ of sample indices $ \{1,2,\dots,N\} $, which has two disjunctive subsets: $ I^M $ for missing positions and $ I^R $ stands for reliable positions.
Usually, samples $ \mathbf{s}(I^R) $ are considered reliable (undamaged) and $ \mathbf{s}(I^M) $ are samples, which we are looking for.
It is common to rewrite it in matrix form:
\begin{equation*}
	\mathbf{s}_{\mathrm{R}} = \mathbf{M}_{\mathrm{R}}\mathbf{s},
\end{equation*}
where $\mathbf{M}_{R} \in \mathbb{R} ^ { |I^R| \times N}$ ($ |I^R|$ denotes the number of indices in the subset $I^R$) is the mask matrix, selecting rows from indentity matrix corresponding to the indices in $I^R$ \cite{Adler2012}.
In words, $\mathbf{M}_{\mathrm{R}}\mathbf{s}$ represents choosing the samples from $\mathbf{s}$ on positions $I^R$.

It is natural to define the set of signals fitting the observation as
\begin{equation}
	\label{eq:Gamma}
	\Gamma = \lbrace \mathbf {y}\in \mathbb {R}^L\mid M_{\mathrm{R}}\mathbf {y}=M_{\mathrm{R}}\mathbf {s}\rbrace.
\end{equation}
In the noise-less case, we would search for a suitable signal in $\Gamma$.
On the other hand, when the observed samples are distorted by noise, we only require the solution \todo{(zavedeme si nějaké značení pro výsledný signál?)} to be close to the set $\Gamma$.


\subsection{COEFFS INPUT Aprroach -- WORK NAME}\label{subsec:freqcoef}
\todo{Pro tento přístup se používá označení syntetizující (\textit{synthesis} nebo \textit{synthesis-based formulation}), pro ten v další části analyzující (\textit{analysis}).}

We define our task as of finding a suitable signal in (or close to) $\Gamma$ as a sparsity-based problem, minimizing $ \ell_0 $-norm of the time-frequency (TF) \todo{(možná hned používat Gabor coefficients, ať dále dává smysl termín Gabor transform)} coefficients of the signal $ \mathbf{s} $.
However, this task leads to an NP-hard problem and is hardly solvable \cite{Mokry2020}.
The closest redefinition is to use the $ \ell_1 $ norm as follows:

\begin{equation}
 \mathop {\operatorname{arg \, min}}_\mathbf {c}\Vert \mathbf {c}\Vert _1 \quad \text{s.t.}\ D\mathbf {c}\in \Gamma
\end{equation} 
where $ D $ is synthesis operator (inverse discrete Gabor transform) and we assume $ A $, $ D = A^* $ and therefore the reconstructed signal corresponds to $ \mathbf {y} \approx  D\mathbf {c}$.
\todo{Je správně $ \mathbf {y} \approx  D\mathbf {c}$, nebo $ \mathbf {y} =  D\mathbf {c}$?}

\todo{Definici $\Gamma$ jsem posunul výše.}
% Set $ \Gamma $ is defined as follows:

%\begin{equation}
%	\label{eq:Gamma}
%	\Gamma = \lbrace \mathbf {y}\in \mathbb {R}^L\mid M_{\mathrm{R}}\mathbf {y}=M_{\mathrm{R}}\mathbf {s}\rbrace,
%\end{equation}

One of the suitable solutions is DR algorithm in \ref{alg:DRA_c} \cite{Mokry2020}.

\begin{algorithm}
	\caption{Douglas-Rachford algorithm -- model with frequency coefficients}
	\begin{algorithmic}[1]\label{alg:DRA_c}
		\renewcommand{\algorithmicrequire}{\textbf{Input:}}
		\renewcommand{\algorithmicensure}{\textbf{Output:}}
		\REQUIRE  $ \gamma > 0 $, $ \delta  \in (0,1)$ ,
		
		\FOR {$n = 0, 1, \dots$}
		\STATE $\mathbf{\widetilde{c}}_n=\operatorname{proj}_{\Gamma}(\mathbf{c}_n) $ 
		\STATE $ \mathbf{c}_{n+1} = \mathbf{c}_n + \lambda \left( \operatorname{soft}_{\gamma}\left(2\mathbf{\widetilde{c}}_n-\mathbf{c}_n \right)-\mathbf{\widetilde{c}}_n\right)$
		\ENDFOR
		\RETURN $D(\operatorname{proj}_{\Gamma}(\mathbf{c}_n))$ 
	\end{algorithmic} 
\end{algorithm}
Operator $ \operatorname{proj}_{\Gamma}(arg)$ is projection onto convex set $ \Gamma $ and $\operatorname{soft}_{\gamma}(arg)$ is soft thresholding operator.
Both are proximal operators.

The condition   $ \delta  \in (0,1)$ is strict for convergence of solution \cite{Combettes2011}.


\subsection{SAMPLES as INPUT APPROACH}\label{subsec:timecoef}

Second approach uses time domain samples as input.
It has mainly computational advice against first approach, in algorithm are less time-frequency transformations (e.g less multiplication operations per iteration).
Problem is, 
that we do not know proximal operator of $ \ell_1 $ norm after analysis, but we can use approximal operator \cite{Mokry2021}.

The main minimazation task reformulates as:
\begin{equation}
	\mathop {\operatorname{arg \, min}}_\mathbf {s}\Vert \mathbf {s}\Vert _1 \quad \text{s.t.}\ \mathbf {s}\in \Gamma,
\end{equation} 
and $ \Gamma $ is similarly as in \eqref{eq:Gamma} % Tags???????  
\todo{Tuto rovnici tu máme dvakrát.}
\begin{equation}
	\Gamma = \lbrace \mathbf {s}\in \mathbb {R}^N\mid M_{\mathrm{R}}\mathbf {y}=M_{\mathrm{R}}\mathbf {s}\rbrace.
\end{equation}
Afterwards our algorithm resolves to following: 
\begin{algorithm}
	\caption{Douglas-Rachford algorithm -- model with time coefficients}
	\begin{algorithmic}[1]\label{alg:DRA_t}
		\renewcommand{\algorithmicrequire}{\textbf{Input:}}
		\renewcommand{\algorithmicensure}{\textbf{Output:}}
		\REQUIRE $ \lambda > 0 $, $ \gamma>0 $, $ \mathbf{x}_0 \in \mathbb{R}^{N} $ \todo{Zmínit, že $\lambda$ může být (a u nás bude) proměnné.}
		\FOR {$n = 0, 1, \dots$}
		\STATE $\mathbf{\widetilde{x}}_n=\operatorname{proj}_{\Gamma}(\mathbf{x}_n) $ 
		\STATE $ \mathbf{x}_{n+1} = \mathbf{x}_n + \lambda \left( D\left(\operatorname{soft}_{\gamma}\left(A\left(2\mathbf{\widetilde{x}}_n-\mathbf{x}_n\right) \right)\right) -\mathbf{\widetilde{x}}_n\right)$
		\ENDFOR
		\RETURN $\operatorname{proj}_{\Gamma}(\mathbf{x}_n)$ 
	\end{algorithmic} 
\end{algorithm}

Projection, in this case, is simply replacing reconstructed samples in positions considered reliable.

\section{Plug-and-Play inpainting} \label{sec:plugaandplay}

\subsection{general algorithm}

\begin{algorithm}
	\caption{Plug-and-Play DR algorithm}
	\begin{algorithmic}[1]
		\renewcommand{\algorithmicrequire}{\textbf{Input:}}
		\renewcommand{\algorithmicensure}{\textbf{Output:}}
		\REQUIRE in
		\FOR {$n = 0, 1, \dots$}
		\STATE $\mathbf{\widetilde{x}}_n=\operatorname{proj}_{\Gamma}(\mathbf{x}_n) $ 
		\STATE $ \mathbf{x}_{n+1} = \mathbf{x}_n + \lambda \left( \mathcal{D} \left(2\mathbf{\widetilde{x}}_n-\mathbf{x}_n \right)-\mathbf{\widetilde{x}}_n\right)$
		\ENDFOR
		\RETURN $\operatorname{proj}_{\Gamma}(\mathbf{x}_n)$ 
	\end{algorithmic} 
\end{algorithm}
\subsection{choice of denoiser}

\subsection{Denoisers}

\section{Testing data and evaluation}\label{sec:eval}


\section{Conclusion}
\label{sec:conclusion}

\todo{Naše metoda je super (až na to, že nefunguje, ale to nebudeme říkat).}

\todo{Dalším postupem bude testovat použití na jiné související úlohy dle principu plug-and-play (declipping, dekvantizace). Nabízí se zkusit nepoužívat off-the-shelf denoiser, ale vlastní, který je učený na datech příbuzných s naší úlohou (např.\ specifický šum vzniklý výpadkem jistého procenta vzorků). Taktéž by se nabízel transfer learning, tj.\ vzít dobrý denoiser a jenom ho doučit, aby byl schopný redukovat artefakty vzniklé v inpaintovací úloze.}

%\section*{Acknowledgment}
%
%The preferred spelling of the word ``acknowledgment'' in America is without 
%an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
%G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
%acknowledgments in the unnumbered footnote on the first page.

\bibliographystyle{IEEEtr}
\bibliography{bib_eeict2023}



\end{document}
