 
@TechReport{Pascual2017,
  author     = {Pascual, Santiago and Bonafonte, Antonio and Serrà, Joan},
  title      = {{SEGAN}: {Speech} {Enhancement} {Generative} {Adversarial} {Network}},
  year       = {2017},
  month      = jun,
  note       = {arXiv:1703.09452 [cs] type: article},
  abstract   = {Current speech enhancement techniques operate on the spectral domain and/or exploit some higher-level feature. The majority of them tackle a limited number of noise conditions and rely on first-order statistics. To circumvent these issues, deep networks are being increasingly used, thanks to their ability to learn complex functions from large example sets. In this work, we propose the use of generative adversarial networks for speech enhancement. In contrast to current techniques, we operate at the waveform level, training the model end-to-end, and incorporate 28 speakers and 40 different noise conditions into the same model, such that model parameters are shared across them. We evaluate the proposed model using an independent, unseen test set with two speakers and 20 alternative noise conditions. The enhanced samples confirm the viability of the proposed model, and both objective and subjective evaluations confirm the effectiveness of it. With that, we open the exploration of generative architectures for speech enhancement, which may progressively incorporate further speech-centric design choices to improve their performance.},
  annote     = {Comment: 5 pages, 4 figures, accepted in INTERSPEECH 2017},
  doi        = {10.48550/arXiv.1703.09452},
  file       = {:Pascual2017 - SEGAN_ Speech Enhancement Generative Adversarial Network.pdf:PDF},
  keywords   = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Sound},
  school     = {arXiv},
  shorttitle = {{SEGAN}},
  url        = {http://arxiv.org/abs/1703.09452},
  urldate    = {2023-02-22},
}

 
@TechReport{Chan2016,
  author     = {Chan, Stanley H. and Wang, Xiran and Elgendy, Omar A.},
  title      = {Plug-and-{Play} {ADMM} for {Image} {Restoration}: {Fixed} {Point} {Convergence} and {Applications}},
  year       = {2016},
  month      = nov,
  note       = {arXiv:1605.01710 [cs] type: article},
  abstract   = {Alternating direction method of multiplier (ADMM) is a widely used algorithm for solving constrained optimization problems in image restoration. Among many useful features, one critical feature of the ADMM algorithm is its modular structure which allows one to plug in any off-the-shelf image denoising algorithm for a subproblem in the ADMM algorithm. Because of the plug-in nature, this type of ADMM algorithms is coined the name "Plug-and-Play ADMM". Plug-and-Play ADMM has demonstrated promising empirical results in a number of recent papers. However, it is unclear under what conditions and by using what denoising algorithms would it guarantee convergence. Also, since Plug-and-Play ADMM uses a specific way to split the variables, it is unclear if fast implementation can be made for common Gaussian and Poissonian image restoration problems. In this paper, we propose a Plug-and-Play ADMM algorithm with provable fixed point convergence. We show that for any denoising algorithm satisfying an asymptotic criteria, called bounded denoisers, Plug-and-Play ADMM converges to a fixed point under a continuation scheme. We also present fast implementations for two image restoration problems on super-resolution and single-photon imaging. We compare Plug-and-Play ADMM with state-of-the-art algorithms in each problem type, and demonstrate promising experimental results of the algorithm.},
  annote     = {Comment: 14 pages},
  doi        = {10.48550/arXiv.1605.01710},
  file       = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1605.01710.pdf:application/pdf},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition},
  school     = {arXiv},
  shorttitle = {Plug-and-{Play} {ADMM} for {Image} {Restoration}},
  url        = {http://arxiv.org/abs/1605.01710},
  urldate    = {2023-02-22},
}

 
@Article{Mokry2020,
  author     = {Mokrý, Ondřej and Rajmic, Pavel},
  journal    = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title      = {Audio {Inpainting}: {Revisited} and {Reweighted}},
  year       = {2020},
  issn       = {2329-9304},
  pages      = {2906--2918},
  volume     = {28},
  abstract   = {In this article, we deal with the problem of sparsity-based audio inpainting, i.e. filling in the missing segments of audio. A consequence of the approaches based on mathematical optimization is the insufficient amplitude of the signal in the filled gaps. Remaining in the framework based on sparsity and convex optimization, we propose improvements to audio inpainting, aiming at compensating for such an energy loss. The new ideas are based on different types of weighting, both in the coefficient and the time domains. We show that our propositions improve the inpainting performance in terms of both the SNR and ODG.},
  doi        = {10.1109/TASLP.2020.3030486},
  file       = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=9222235&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzkyMjIyMzU=:application/pdf},
  keywords   = {Transforms, Reliability, Speech processing, Microsoft Windows, Analytical models, Minimization, Time-domain analysis, Audio inpainting, sparse representations, proximal algorithms, Douglas–Rachford algorithm, Chambolle–Pock algorithm, energy loss compensation, amplitude drop},
  shorttitle = {Audio {Inpainting}},
}

 
@Article{Janssen1986,
  author   = {Janssen, A. and Veldhuis, R. and Vries, L.},
  journal  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title    = {Adaptive interpolation of discrete-time signals that can be modeled as autoregressive processes},
  year     = {1986},
  issn     = {0096-3518},
  month    = apr,
  number   = {2},
  pages    = {317--330},
  volume   = {34},
  abstract = {This paper presents an adaptive algorithm for the restoration of lost sample values in discrete-time signals that can locally be described by means of autoregressive processes. The only restrictions are that the positions of the unknown samples should be known and that they should be embedded in a sufficiently large neighborhood of known samples. The estimates of the unknown samples are obtained by minimizing the sum of squares of the residual errors that involve estimates of the autoregressive parameters. A statistical analysis shows that, for a burst of lost samples, the expected quadratic interpolation error per sample converges to the signal variance when the burst length tends to infinity. The method is in fact the first step of an iterative algorithm, in which in each iteration step the current estimates of the missing samples are used to compute the new estimates. Furthermore, the feasibility of implementation in hardware for real-time use is established. The method has been tested on artificially generated auto-regressive processes as well as on digitized music and speech signals.},
  doi      = {10.1109/TASSP.1986.1164824},
  file     = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=1164824&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzExNjQ4MjQ=:application/pdf},
  keywords = {Interpolation, Signal processing, Autoregressive processes, Adaptive algorithm, Signal restoration, Statistical analysis, H infinity control, Iterative algorithms, Hardware, Testing},
}

 
@Article{Etter1996,
  author   = {Etter, W.},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {Restoration of a discrete-time signal segment by interpolation based on the left-sided and right-sided autoregressive parameters},
  year     = {1996},
  issn     = {1941-0476},
  month    = may,
  number   = {5},
  pages    = {1124--1135},
  volume   = {44},
  abstract = {This paper presents an algorithm for the interpolation of a missing signal segment on the assumption that the signal can be modeled as an autoregressive (AR) process. Unlike previous algorithms, the presented algorithm does not model the signal of the missing segment and the neighboring signal portions by a single AR-parameter vector. Instead, two separate vectors are used so that stationarity need no longer be assumed to extend beyond both sides of the missing segment. The relaxation of this stationarity assumption is essential when the duration of the missing segment is on the order of the short-time stationarity duration of the signal. The algorithm provides the optimal solution to the problem of interpolating a missing segment based on the left-sided and right-sided AR-parameter vectors. The solution is optimal in the sense of a least-squares residual. The algorithm is applied to speech and music signals and is compared with other restoration techniques.},
  doi      = {10.1109/78.502326},
  file     = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=502326&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzUwMjMyNg==:application/pdf},
  keywords = {Signal restoration, Interpolation, Signal processing, Speech, Extrapolation, Iterative algorithms, Multiple signal classification, Sampling methods, Audio tapes, Audio recording},
}

 
@InProceedings{Mokry2019,
  author    = {Mokrý, Ondřej and Záviška, Pavel and Rajmic, Pavel and Veselý, Vítězslav},
  booktitle = {2019 27th {European} {Signal} {Processing} {Conference} ({EUSIPCO})},
  title     = {Introducing {SPAIN} ({SParse} {Audio} {INpainter})},
  year      = {2019},
  month     = sep,
  note      = {ISSN: 2076-1465},
  pages     = {1--5},
  abstract  = {A novel sparsity-based algorithm for audio inpainting is proposed. It is an adaptation of the SPADE algorithm by Kitić et al., originally developed for audio declipping, to the task of audio inpainting. The new SPAIN (SParse Audio INpainter) comes in synthesis and analysis variants. Experiments show that both A-SPAIN and S-SPAIN outperform other sparsity-based inpainting algorithms. Moreover, A-SPAIN performs on a par with the state-of-the-art method based on linear prediction in terms of the SNR, and, for larger gaps, SPAIN is even slightly better in terms of the PEMO-Q psychoacoustic criterion.},
  doi       = {10.23919/EUSIPCO.2019.8902560},
  file      = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=8902560&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50Lzg5MDI1NjA=:application/pdf},
  issn      = {2076-1465},
  keywords  = {Task analysis, Signal processing algorithms, Approximation algorithms, Signal to noise ratio, Reliability, Time-domain analysis, Inpainting, Sparse, Cosparse, Synthesis, Analysis},
}

 
@Article{Adler2012,
  author   = {Adler, Amir and Emiya, Valentin and Jafari, Maria and Elad, Michael and Gribonval, Remi and Plumbley, Mark},
  journal  = {IEEE Transactions on Audio Speech and Language Processing},
  title    = {Audio {Inpainting}},
  year     = {2012},
  month    = mar,
  pages    = {922--932},
  volume   = {20},
  abstract = {We propose the audio inpainting framework that recovers portions of audio data distorted due to impairments such as impulsive noise, clipping, and packet loss. In this framework, the distorted data are treated as missing and their location is assumed to be known. The signal is decomposed into overlapping time-domain frames and the restoration problem is then formulated as an inverse problem per audio frame. Sparse representation modeling is employed per frame, and each inverse problem is solved using the Orthogonal Matching Pursuit algorithm together with a discrete cosine or a Gabor dictionary. The Signal-to-Noise Ratio performance of this algorithm is shown to be comparable or better than state-of-the-art methods when blocks of samples of variable durations are missing. We also demonstrate that the size of the block of missing samples, rather than the overall number of missing samples, is a crucial parameter for high quality signal restoration. We further introduce a constrained Matching Pursuit approach for the special case of audio declipping that exploits the sign pattern of clipped audio samples and their maximal absolute value, as well as allowing the user to specify the maximum amplitude of the signal. This approach is shown to outperform state-of-the-art and commercially available methods for audio declipping in terms of Signal-to-Noise Ratio.},
  doi      = {10.1109/TASL.2011.2168211},
  file     = {Full Text PDF:https\://www.researchgate.net/profile/Amir-Adler/publication/224258540_Audio_Inpainting/links/55df72c808ae6abe6e8652dc/Audio-Inpainting.pdf:application/pdf;ResearchGate Link:https\://www.researchgate.net/publication/224258540_Audio_Inpainting:},
}

 
@TechReport{Kitic2015,
  author     = {Kitić, Srđan and Bertin, Nancy and Gribonval, Rémi},
  title      = {Sparsity and cosparsity for audio declipping: a flexible non-convex approach},
  year       = {2015},
  month      = jun,
  note       = {arXiv:1506.01830 [cs] type: article},
  abstract   = {This work investigates the empirical performance of the sparse synthesis versus sparse analysis regularization for the ill-posed inverse problem of audio declipping. We develop a versatile non-convex heuristics which can be readily used with both data models. Based on this algorithm, we report that, in most cases, the two models perform almost similarly in terms of signal enhancement. However, the analysis version is shown to be amenable for real time audio processing, when certain analysis operators are considered. Both versions outperform state-of-the-art methods in the field, especially for the severely saturated signals.},
  doi        = {10.48550/arXiv.1506.01830},
  file       = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1506.01830.pdf:application/pdf},
  keywords   = {Computer Science - Sound},
  school     = {arXiv},
  shorttitle = {Sparsity and cosparsity for audio declipping},
  url        = {http://arxiv.org/abs/1506.01830},
  urldate    = {2023-02-27},
}

 
@InProceedings{Zaviska2019,
  author    = {Záviška, Pavel and Rajmic, Pavel and Mokrý, Ondřej and Průša, Zdeněk},
  booktitle = {{ICASSP} 2019 - 2019 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
  title     = {A {Proper} {Version} of {Synthesis}-based {Sparse} {Audio} {Declipper}},
  year      = {2019},
  month     = may,
  note      = {ISSN: 2379-190X},
  pages     = {591--595},
  abstract  = {Methods based on sparse representation have found great use in the recovery of audio signals degraded by clipping. The state of the art in declipping within the sparsity-based approaches has been achieved by the SPADE algorithm by Kitić et. al. (LVA/ICA'15). Our recent study (LVA/ICA'18) has shown that although the original S-SPADE can be improved such that it converges faster than the A-SPADE, the restoration quality is significantly worse. In the present paper, we propose a new version of S-SPADE. Experiments show that the novel version of S-SPADE outperforms its old version in terms of restoration quality, and that it is comparable with the A-SPADE while being even slightly faster than A-SPADE.},
  doi       = {10.1109/ICASSP.2019.8682348},
  file      = {IEEE Xplore Full Text PDF:https\://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=8682348&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50Lzg2ODIzNDg=:application/pdf},
  issn      = {2379-190X},
  keywords  = {Convex functions, Time-domain analysis, Discrete Fourier transforms, Minimization, Approximation algorithms, Redundancy, Declipping, Sparse, Cosparse, Synthesis, Analysis},
}

 
@TechReport{Hao2021,
  author     = {Hao, Xiang and Su, Xiangdong and Horaud, Radu and Li, Xiaofei},
  title      = {{FullSubNet}: {A} {Full}-{Band} and {Sub}-{Band} {Fusion} {Model} for {Real}-{Time} {Single}-{Channel} {Speech} {Enhancement}},
  year       = {2021},
  month      = jan,
  note       = {arXiv:2010.15508 [cs, eess] type: article},
  abstract   = {This paper proposes a full-band and sub-band fusion model, named as FullSubNet, for single-channel real-time speech enhancement. Full-band and sub-band refer to the models that input full-band and sub-band noisy spectral feature, output full-band and sub-band speech target, respectively. The sub-band model processes each frequency independently. Its input consists of one frequency and several context frequencies. The output is the prediction of the clean speech target for the corresponding frequency. These two types of models have distinct characteristics. The full-band model can capture the global spectral context and the long-distance cross-band dependencies. However, it lacks the ability to modeling signal stationarity and attending the local spectral pattern. The sub-band model is just the opposite. In our proposed FullSubNet, we connect a pure full-band model and a pure sub-band model sequentially and use practical joint training to integrate these two types of models' advantages. We conducted experiments on the DNS challenge (INTERSPEECH 2020) dataset to evaluate the proposed method. Experimental results show that full-band and sub-band information are complementary, and the FullSubNet can effectively integrate them. Besides, the performance of the FullSubNet also exceeds that of the top-ranked methods in the DNS Challenge (INTERSPEECH 2020).},
  annote     = {Comment: 5 pages, submitted to 2021 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2021)},
  doi        = {10.48550/arXiv.2010.15508},
  file       = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2010.15508.pdf:application/pdf},
  keywords   = {Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Sound, Electrical Engineering and Systems Science - Signal Processing},
  school     = {arXiv},
  shorttitle = {{FullSubNet}},
  url        = {http://arxiv.org/abs/2010.15508},
  urldate    = {2023-02-27},
}

 
@TechReport{Xia2020,
  author   = {Xia, Yangyang and Braun, Sebastian and Reddy, Chandan K. A. and Dubey, Harishchandra and Cutler, Ross and Tashev, Ivan},
  title    = {Weighted {Speech} {Distortion} {Losses} for {Neural}-network-based {Real}-time {Speech} {Enhancement}},
  year     = {2020},
  month    = feb,
  note     = {arXiv:2001.10601 [cs, eess] type: article},
  abstract = {This paper investigates several aspects of training a RNN (recurrent neural network) that impact the objective and subjective quality of enhanced speech for real-time single-channel speech enhancement. Specifically, we focus on a RNN that enhances short-time speech spectra on a single-frame-in, single-frame-out basis, a framework adopted by most classical signal processing methods. We propose two novel mean-squared-error-based learning objectives that enable separate control over the importance of speech distortion versus noise reduction. The proposed loss functions are evaluated by widely accepted objective quality and intelligibility measures and compared to other competitive online methods. In addition, we study the impact of feature normalization and varying batch sequence lengths on the objective quality of enhanced speech. Finally, we show subjective ratings for the proposed approach and a state-of-the-art real-time RNN-based method.},
  doi      = {10.48550/arXiv.2001.10601},
  file     = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2001.10601.pdf:application/pdf},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Sound},
  school   = {arXiv},
  url      = {http://arxiv.org/abs/2001.10601},
  urldate  = {2023-02-27},
}

 
@Article{Mokry2021,
  author   = {Mokrý, Ondřej and Rajmic, Pavel},
  journal  = {Signal Processing},
  title    = {Approximal operator with application to audio inpainting},
  year     = {2021},
  issn     = {0165-1684},
  month    = feb,
  pages    = {107807},
  volume   = {179},
  abstract = {In their recent evaluation of time-frequency representations and structured sparsity approaches to audio inpainting, Lieb and Stark (2018) have used a particular mapping as a proximal operator. This operator serves as the fundamental part of an iterative numerical solver. However, their mapping is improperly justified. The present article proves that their mapping is indeed a proximal operator, and also derives its proper counterpart. Furthermore, it is rationalized that Lieb and Stark’s operator can be understood as an approximation of the proper mapping. Surprisingly, in most cases, such an approximation (referred to as the approximal operator) is shown to provide even better numerical results in audio inpainting compared to its proper counterpart, while being computationally much more effective.},
  doi      = {10.1016/j.sigpro.2020.107807},
  file     = {ScienceDirect Full Text PDF:https\://www.sciencedirect.com/science/article/pii/S0165168420303510/pdfft?md5=82adb89ddc72eaa72a97eab0111b08c1&pid=1-s2.0-S0165168420303510-main.pdf&isDTMRedir=Y:application/pdf},
  keywords = {Proximal operator, Proximal algorithms, Approximation, Sparsity, Audio inpainting},
  language = {en},
  url      = {https://www.sciencedirect.com/science/article/pii/S0165168420303510},
  urldate  = {2023-03-05},
}

 
@TechReport{Combettes2010,
  author   = {Combettes, Patrick L. and Pesquet, Jean-Christophe},
  title    = {Proximal {Splitting} {Methods} in {Signal} {Processing}},
  year     = {2010},
  month    = may,
  note     = {arXiv:0912.3522 [math] type: article},
  abstract = {The proximity operator of a convex function is a natural extension of the notion of a projection operator onto a convex set. This tool, which plays a central role in the analysis and the numerical solution of convex optimization problems, has recently been introduced in the arena of signal processing, where it has become increasingly important. In this paper, we review the basic properties of proximity operators which are relevant to signal processing and present optimization methods based on these operators. These proximal splitting methods are shown to capture and extend several well-known algorithms in a unifying framework. Applications of proximal methods in signal recovery and synthesis are discussed.},
  doi      = {10.48550/arXiv.0912.3522},
  file     = {arXiv Fulltext PDF:https\://arxiv.org/pdf/0912.3522.pdf:application/pdf},
  keywords = {Mathematics - Optimization and Control, Mathematics - Numerical Analysis, 90C25, 65K05, 90C90, 94A08},
  school   = {arXiv},
  url      = {http://arxiv.org/abs/0912.3522},
  urldate  = {2023-03-06},
}

@Comment{jabref-meta: databaseType:bibtex;}
